{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca5ac93c",
   "metadata": {},
   "source": [
    "#### 1. Pick one of the datasets from the ChatBot session(s) of the **TUT demo** (or from your own ChatBot session if you wish) and use the code produced through the ChatBot interactions to import the data and confirm that the dataset has missing values<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ec425f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "row_n           0\n",
       "id              1\n",
       "name            0\n",
       "gender          0\n",
       "species         0\n",
       "birthday        0\n",
       "personality     0\n",
       "song           11\n",
       "phrase          0\n",
       "full_id         0\n",
       "url             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# feel free to just use the following if you prefer...\n",
    "import pandas as pd\n",
    "url = \"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-05-05/villagers.csv\"\n",
    "df = pd.read_csv(url)\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e2d47a3",
   "metadata": {},
   "source": [
    "#### 2. Start a new ChatBot session with an initial prompt introducing the dataset you're using and request help to determine how many columns and rows of data a `pandas` DataFrame has, and then\n",
    "\n",
    "1. use code provided in your ChatBot session to print out the number of rows and columns of the dataset; and,  \n",
    "2. write your own general definitions of the meaning of \"observations\" and \"variables\" based on asking the ChatBot to explain these terms in the context of your dataset<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "24c18854",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(391, 11)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d06fc6",
   "metadata": {},
   "source": [
    "Observations typically refer to the number of rows in the dataset, with each row representing a different data entry or instance.\n",
    "\n",
    "Variables refer to the number of columns in the dataset, with each column representing a different characteristic or attribute."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc4c50e6",
   "metadata": {},
   "source": [
    "#### 3. Ask the ChatBot how you can provide simple summaries of the columns in the dataset and use the suggested code to provide these summaries for your dataset<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a4725808",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_n</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>391.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>239.902813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>140.702672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>117.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>240.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>363.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>483.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            row_n\n",
       "count  391.000000\n",
       "mean   239.902813\n",
       "std    140.702672\n",
       "min      2.000000\n",
       "25%    117.500000\n",
       "50%    240.000000\n",
       "75%    363.500000\n",
       "max    483.000000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "386f7d72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "birthday\n",
       "1-27     2\n",
       "12-5     2\n",
       "7-31     2\n",
       "3-26     2\n",
       "8-3      2\n",
       "        ..\n",
       "4-3      1\n",
       "10-26    1\n",
       "7-23     1\n",
       "12-8     1\n",
       "3-8      1\n",
       "Name: count, Length: 361, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['birthday'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71877308",
   "metadata": {},
   "source": [
    "#### 4. If the dataset you're using has (a) non-numeric variables and (b) missing values in numeric variables, explain (perhaps using help from a ChatBot if needed) the discrepancies between size of the dataset given by `df.shape` and what is reported by `df.describe()` with respect to (a) the number of columns it analyzes and (b) the values it reports in the \"count\" column<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be37024f",
   "metadata": {},
   "source": [
    "df.shape provides a high-level overview of the dimensions of the dataset, without regard to data types or missing values.\n",
    "\n",
    "df.describe() focuses on numeric columns and may show discrepancies in counts if there are missing values.\n",
    "\n",
    "Use df.describe(include='all') to get a summary of both numeric and non-numeric columns.\n",
    "\n",
    "Understanding these differences will help you to better interpret the statistics and summaries provided by these methods, and to handle missing values and data types appropriately."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a1cfbb4",
   "metadata": {},
   "source": [
    "#### 5. Use your ChatBot session to help understand the difference between the following and then provide your own paraphrasing summarization of that difference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6379db6b",
   "metadata": {},
   "source": [
    "df.shape is an attribute of the DataFrame df. It returns the dimensions of the DataFrame as a tuple (number_of_rows, number_of_columns).\n",
    "It does not need parentheses because it is not a function or method that performs an action; it simply returns a value.\n",
    "\n",
    "df.describe() is a method of the DataFrame df. It computes and returns a summary of statistics for the numeric columns in the DataFrame.\n",
    "It requires parentheses because it is a function that performs a computation or operation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f9ae28e",
   "metadata": {},
   "source": [
    "#### 6. The `df.describe()` method provides the 'count', 'mean', 'std', 'min', '25%', '50%', '75%', and 'max' summary statistics for each variable it analyzes. Give the definitions (perhaps using help from the ChatBot if needed) of each of these summary statistics<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "088bd51e",
   "metadata": {},
   "source": [
    "1. Count\n",
    "Definition: The number of non-missing (non-null) entries in each column.\n",
    "Explanation: This statistic shows how many valid (non-missing) data points are present in each column.\n",
    "2. Mean\n",
    "Definition: The average of the numeric entries in each column.\n",
    "Explanation: The mean provides a measure of the central tendency of the data.\n",
    "3. Standard Deviation (std)\n",
    "Definition: A measure of the amount of variation or dispersion in the numerical entries of each column.\n",
    "Explanation: The standard deviation quantifies how spread out the values are around the mean.  4. Minimum (min)\n",
    "Definition: The smallest value among the numeric entries in each column.\n",
    "Explanation: This statistic indicates the lowest boundary of the data.\n",
    "5. 25th Percentile (25%)\n",
    "Definition: The value below which 25% of the data falls.\n",
    "Explanation: Also known as the first quartile, this percentile represents the lower boundary of the bottom 25% of the data. \n",
    "6. 50th Percentile (50%)\n",
    "Definition: The median of the numeric entries in each column.\n",
    "Explanation: The median divides the data into two equal halves, with 50% of the data falling below and 50% above this value.\n",
    "7. 75th Percentile (75%)\n",
    "Definition: The value below which 75% of the data fall.\n",
    "Explanation: Also known as the third quartile, this percentile represents the upper boundary of the lower 75% of the data.\n",
    "8. Maximum (Max)\n",
    "Definition: The largest value among the numeric entries in each column.\n",
    "Explanation: This statistic represents the upper bound of the data.\n",
    "Summary Statistics\n",
    "Count: Number of non-missing entries.\n",
    "Mean: Average value.\n",
    "Standard deviation: Measure of the spread of the data.\n",
    "Minimum: Smallest value.\n",
    "25th Percentile: Value below which 25% of the data falls.\n",
    "50th Percentile: Median value.\n",
    "75th Percentile: Value below which 75% of the data fall.\n",
    "Maximum: Largest value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be334bf4",
   "metadata": {},
   "source": [
    "#### 7. Missing data can be considered \"across rows\" or \"down columns\".  Consider how `df.dropna()` or `del df['col']` should be applied to most efficiently use the available non-missing data in your dataset and briefly answer the following questions in your own words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dd3d66e",
   "metadata": {},
   "source": [
    "1. Provide an example of a \"use case\" in which using `df.dropna()` might be peferred over using `del df['col']`<br><br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "101fd651",
   "metadata": {},
   "source": [
    "Scenario:\n",
    "You are working on a predictive modeling project where you need to build a machine learning model to predict survival on the Titanic using the Titanic dataset. The dataset contains several columns with missing values, such as \"age\", \"embarked\", and \"ship\". Your goal is to ensure that your model is trained on data that has no missing values in the features used for training.\n",
    "\n",
    "Why Use df.dropna()?\n",
    "Ensure complete data for modeling:\n",
    "\n",
    "Purpose: For machine learning algorithms, especially those that cannot handle missing values internally (like many algorithms in scikit-learn), it is crucial that the input features used for training do not contain missing values.\n",
    "For example: You decide to use the columns 'age' and 'embarked' as features. Using df.dropna(), you can remove rows where either 'age' or 'embarked' is missing, ensuring that the rows used for training have complete data for these features.\n",
    "Handling multiple columns:\n",
    "\n",
    "Purpose: If multiple columns have missing values, and you want to ensure that your training data is complete in all of these columns, df.dropna() helps by removing rows with missing values in any of the specified columns.\n",
    "Example: You may not know in advance which columns will be important for your model. By using df.dropna(), you ensure that any row with missing values in any of the selected columns is removed, keeping your data set consistent.\n",
    "Preserving the Data Set Structure:\n",
    "\n",
    "Purpose: When you use df.dropna(), you remove only rows with missing values, preserving the overall structure of the data set and all remaining columns.\n",
    "Example: If you need to keep all columns in your data set, but only want to remove incomplete rows, df.dropna() preserves the columns of the data set while removing rows with missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8077ccc",
   "metadata": {},
   "source": [
    "2. Provide an example of \"the opposite use case\" in which using `del df['col']` might be preferred over using `df.dropna()` <br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35192fcf",
   "metadata": {},
   "source": [
    "Scenario:\n",
    "You are performing exploratory data analysis (EDA) on the Titanic dataset and have determined that certain columns do not provide meaningful information for your analysis or may be redundant. For example, you may find that the Boat column, which represents the boat number, has very few non-null values and does not provide significant insight or value to your analysis. Removing this column could simplify your data set and make your analysis more focused.\n",
    "\n",
    "Why use del df['col']?\n",
    "1. Simplify the dataset:\n",
    "\n",
    "Purpose: To streamline the data set by removing columns that are irrelevant or redundant, especially if they have many missing values or do not contribute to the analysis. This makes the data set easier to manage and analyze.\n",
    "\n",
    "Solution: del df['col'] can be used to remove specific columns, such as 'boat', that are not useful for your analysis, thus simplifying the data set.\n",
    "\n",
    "2. Reduce data size:\n",
    "\n",
    "Purpose: Large datasets with many columns can become unwieldy, and having unnecessary columns can make the dataset more cumbersome to work with. Removing unnecessary columns can reduce memory usage and improve performance.\n",
    "\n",
    "Solution: Using del df['boat'] reduces the size of the data set and improves its manageability, especially if the column contains mostly missing values or irrelevant information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4fdf556",
   "metadata": {},
   "source": [
    "3. Discuss why applying `del df['col']` before `df.dropna()` when both are used together could be important<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ea8185",
   "metadata": {},
   "source": [
    "Reasons for using del df['col'] before df.dropna()\n",
    "Optimize the data cleaning process:\n",
    "\n",
    "Purpose: Removing irrelevant or redundant columns before dropping rows with missing values can make the data cleaning process more efficient and focused.\n",
    "\n",
    "Example: If a column contains mostly irrelevant data or is unnecessary for your analysis (e.g., a column with unique IDs or a non-informative characteristic), removing it first with del df['col'] reduces the complexity of the DataFrame. You can then use df.dropna() to handle missing values in the remaining relevant columns.\n",
    "\n",
    "Avoid unnecessary operations:\n",
    "\n",
    "Purpose: Applying df.dropna() to columns that are not needed can result in unnecessary operations and computations. Removing such columns first ensures that df.dropna() only operates on columns that are relevant.\n",
    "\n",
    "For example: If you have a column that you know will always have missing values and is irrelevant to your analysis, removing it with del df['col'] avoids the extra step of dropping rows with missing values in that column later. This reduces the amount of data processed and speeds up the cleanup process.\n",
    "\n",
    "Reduce data size and complexity:\n",
    "\n",
    "Purpose: By removing unneeded columns, you simplify the data set. This can lead to better performance and more manageable data cleaning operations.\n",
    "\n",
    "Example: If your DataFrame has many columns, and some of these columns are irrelevant, using del df['col'] helps to reduce the size of the DataFrame. Then using df.dropna() on the smaller, more relevant DataFrame improves efficiency and makes the data cleanup process easier.\n",
    "\n",
    "Improve clarity and focus:\n",
    "\n",
    "Purpose: Cleaning up the data set by removing unneeded columns first can help you focus on the columns that are important to your analysis or model.\n",
    "\n",
    "Example: If you are focusing on a subset of features for model training or analysis, removing irrelevant columns first with del df['col'] ensures that df.dropna() deals only with the important columns. This prevents rows from being accidentally dropped due to missing values in non-essential columns.\n",
    "\n",
    "Avoid misinterpretation of results:\n",
    "\n",
    "Purpose: Ensuring that df.dropna() does not accidentally drop rows based on irrelevant columns helps maintain the integrity of your data analysis or modeling.\n",
    "\n",
    "Example: If a column with many missing values is dropped first, df.dropna() will only consider the remaining columns for missing value handling. This ensures that the results of the missing value removal process are not skewed by irrelevant columns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "127e6a3a",
   "metadata": {},
   "source": [
    "4. Remove all missing data from one of the datasets you're considering using some combination of `del df['col']` and/or `df.dropna()` and give a justification for your approach, including a \"before and after\" report of the results of your approach for your dataset.<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c75df82f",
   "metadata": {},
   "source": [
    "By removing columns with high proportions of missing data (del df['col']) and then using df.dropna() to remove rows with any remaining missing values, we achieve a cleaned dataset that is more manageable and suitable for analysis or modeling. This approach ensures that the dataset used is complete and focused on relevant features, improving the quality and reliability of subsequent analyses."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43982398",
   "metadata": {},
   "source": [
    "#### 8. Give brief explanations in your own words for any requested answers to the questions below"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "766c1c47",
   "metadata": {},
   "source": [
    "1. Use your ChatBot session to understand what `df.groupby(\"col1\")[\"col2\"].describe()` does and then demonstrate and explain this using a different example from the \"titanic\" data set other than what the ChatBot automatically provide for you"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6f98a345",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "      <th>class</th>\n",
       "      <th>who</th>\n",
       "      <th>adult_male</th>\n",
       "      <th>deck</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alive</th>\n",
       "      <th>alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "      <td>First</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>C</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>yes</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>yes</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "      <td>First</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>C</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>yes</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   survived  pclass     sex   age  sibsp  parch     fare embarked  class  \\\n",
       "0         0       3    male  22.0      1      0   7.2500        S  Third   \n",
       "1         1       1  female  38.0      1      0  71.2833        C  First   \n",
       "2         1       3  female  26.0      0      0   7.9250        S  Third   \n",
       "3         1       1  female  35.0      1      0  53.1000        S  First   \n",
       "4         0       3    male  35.0      0      0   8.0500        S  Third   \n",
       "\n",
       "     who  adult_male deck  embark_town alive  alone  \n",
       "0    man        True  NaN  Southampton    no  False  \n",
       "1  woman       False    C    Cherbourg   yes  False  \n",
       "2  woman       False  NaN  Southampton   yes   True  \n",
       "3  woman       False    C  Southampton   yes  False  \n",
       "4    man        True  NaN  Southampton    no   True  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3d7ec4a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        count       mean        std   min   25%   50%   75%   max\n",
      "sex                                                              \n",
      "female  261.0  27.915709  14.110146  0.75  18.0  27.0  37.0  63.0\n",
      "male    453.0  30.726645  14.678201  0.42  21.0  29.0  39.0  80.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset from the URL\n",
    "url = 'https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv'\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# Group by 'class' and calculate descriptive statistics for the 'age' column\n",
    "result = df.groupby('sex')['age'].describe()\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4b283c0",
   "metadata": {},
   "source": [
    "2. Assuming you've not yet removed missing values in the manner of question \"7\" above, `df.describe()` would have different values in the `count` value for different data columns depending on the missingness present in the original data.  Why do these capture something fundamentally different from the values in the `count` that result from doing something like `df.groupby(\"col1\")[\"col2\"].describe()`?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "125fa4fa",
   "metadata": {},
   "source": [
    "Key differences explained\n",
    "Scope of count measurement:\n",
    "\n",
    "df.describe(): The count here is calculated for the entire data set, column by column. It returns the total number of non-null entries for each column in the entire DataFrame.\n",
    "df.groupby(\"pclass\")[\"age\"].describe(): The count is calculated within each group defined by pclass. Each group (i.e., each class) is evaluated separately, showing the number of non-null age entries within each class group.\n",
    "Impact of missing values:\n",
    "\n",
    "df.describe(): The count value reflects missing data throughout the data set. For columns with missing values, this count will be less than the total number of rows.\n",
    "df.groupby(\"pclass\")[\"age\"].describe(): The count for age in each pclass group reflects non-null entries within that particular class. The count for age will differ between classes based on how many non-null entries are present in each class.\n",
    "Fundamental difference:\n",
    "\n",
    "df.describe() provides a summary of missing values in a global sense, highlighting how much data is missing in each column.\n",
    "df.groupby(\"pclass\")[\"age\"].describe() provides insight into the distribution of missing values in a segmented manner, showing how missing data varies across different groups defined by pclass."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4321abce",
   "metadata": {},
   "source": [
    "3. Intentionally introduce the following errors into your code and report your opinion as to whether it's easier to (a) work in a ChatBot session to fix the errors, or (b) use google to search for and fix errors: first share the errors you get in the ChatBot session and see if you can work with ChatBot to troubleshoot and fix the coding errors, and then see if you think a google search for the error provides the necessary toubleshooting help more quickly than ChatGPT<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "619c2013",
   "metadata": {},
   "source": [
    "ChatGPT can be quite effective for understanding and debugging, especially for general guidance and learning. It provides explanations and suggestions tailored to your code.\n",
    "Google search is often faster for finding specific error messages and solutions directly from documentation or community forums. It is useful for quickly resolving known issues."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e576ffa",
   "metadata": {},
   "source": [
    "#### 9. Have you reviewed the course [wiki-textbook](https://github.com/pointOfive/stat130chat130/wiki) and interacted with a ChatBot (or, if that wasn't sufficient, real people in the course piazza discussion board or TA office hours) to help you understand all the material in the tutorial and lecture that you didn't quite follow when you first saw it?<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd6548de",
   "metadata": {},
   "source": [
    "Yes I have reciewed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ed1bfa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
